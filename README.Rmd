---
output:
  pdf_document: default
  html_document: default
---
The P-Technique with lavaan
======================================================

The purpose of this project is to demonstrate how to fit single-subject structural equation models (SEM) within the p-technique framework. As discussed in the primary manuscript, among the recent introductions to and tutorials on the p-technique family, we believe the method outlined in [Little’s (2013) text](https://www.guilford.com/books/Longitudinal-Structural-Equation-Modeling/Todd-Little/9781462510160) is the most thorough and approachable for non-statistician behavioral researchers. Thus, the approach described herein is based primarily on Little’s text.

```{r set-options, echo = FALSE, cache = FALSE}
options(width = 100)
```

Here we open our first few packages and load the data

```{r, warning = F, message = F}
library(readxl)
library(tidyverse)
library(lubridate)

d <- 
  read_excel("Lindsey.xlsx") %>% 
  mutate(Date = ymd(Date))
```

In this document, we'll use functions and syntax from the [tidyverse](https://www.tidyverse.org), which you might learn about [here](http://r4ds.had.co.nz/transform.html) or [here](http://style.tidyverse.org).

Here we take a glance at the structure of the data.

```{r}
glimpse(d)
```

These data are from one participant, who we'll refer to by the pseudonym "Lindsey." The nine columns in the data are composed of three primary types of variables. These are daily-diary data and `Date` contains a sequential list of the dates from the beginning to the end of the study. The next column, `Meds`, is a dummy variable indicating whether Lindsey took her prescribed AHDH medication that day (i.e., coded 0 = "no", 1 = "yes"). The remaining columns `A3` through `A17` are responses to seven of the [18 ASRS items](https://www.ncbi.nlm.nih.gov/pubmed/15841682). At the beginning of the study, Lindsey indicated these seven items represented her most salient ADHD symptoms. Because this was a daily-diary study, we reworded the items and their anchors to make sense in a daily context. The five Likert-type anchor were labeled

* 0 (*Not at all*)
* 1 (*A little*)
* 2 (*Moderately*)
* 3 (*Most of the time*)
* 4 (*All day long*)

Her items were worded as follows:

* Was it difficult concentrating on what people said to you, even when they spoke to you directly?
* Were you distracted by activities or noises around you?
* Did you fidget or squirm with your hands or your feet when sitting down?
* Was it difficult unwinding or relaxing when you had time to yourself?
* Did you feel overly active or compelled to do things, like you were driven by a motor?
* Did you finish the sentences of other people before they could finish them themselves?
* Was it difficult waiting your turn in when you were supposed to?

Note how the data are in the long format. That is, although we have one participant, Lindsey, her data are presented in 103 rows, each corresponding to a different calendar day.

## Descriptive statistics

If you wanted to get a sense of the distributions of the ASRS items, histograms might be handy.

```{r, fig.width = 8, fig.height = 3.5}
d %>% 
  select(A3:A17) %>% 
  rename(A03 = A3,
         A08 = A8) %>% 
  gather(item, rating) %>% 
  
  ggplot(aes(x = rating)) +
  geom_histogram(binwidth = 1, fill = "chartreuse2", color = "grey92", size = 1/5) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~item, ncol = 4)
```

Happily, their distributions look reasonable. You can get a sense of their values over time with a sequentially-color-coded tile plot.

```{r, fig.width = 8, fig.height = 2, warning = F, message = F}
d %>% 
  select(Date, A3:A17) %>% 
  rename(A03 = A3,
         A08 = A8) %>% 
  gather(item, rating, -Date) %>%
  mutate(rating = factor(rating, levels = c(1:5))) %>% 
  
  ggplot(aes(x = Date, y = item)) +
  geom_tile(aes(fill = rating)) +
  scale_fill_viridis_d(NULL, option = "D",
                     guide = guide_legend(direction = "horizontal",
                                          nrow = 1)) +
  scale_x_date(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(x = NULL, y = NULL) +
  theme(panel.grid      = element_blank(),
        axis.ticks.y    = element_blank(),
        axis.text.y     = element_text(hjust = 0),
        legend.position = "top")
```

And with the [psych package](https://cran.r-project.org/web/packages/psych/index.html), we can use the `describe()` function to get the typical descriptive statistics.

```{r, warning = F, message = F}
library(psych)

d %>% 
  select(A3:A17) %>% 
  describe()
```  

If you look at the tile plot, above, you'll note the several light-gray stripes. Those are occasions for missing values. Here's the breakdown of missing values on the ASRS items by count and percent.

```{r}
d %>% 
  mutate(missing = is.na(A10)) %>% 
  group_by(missing) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(percent = 100 * n / sum(n)) %>% 
  mutate_if(is.double, round, digits = 1)
```

Recall that the items in the ASRS correspond to the [18 criterion A symptoms](https://www.cdc.gov/ncbddd/adhd/diagnosis.html), with the first nine classified as Inattentive and the last nine as hyperactive/impulsive. For the sake of this example, we'll focus on Lindsey's hyperactive/impulsive symptoms, ASRS items 10, 13, 14, 16, and 17. The following code drops the other two, items 3 and 8.

```{r}
d <-
  d %>% 
  select(everything(), -A3, -A8)
```

## P-technique CFA

Here we open our primary statistical package, [lavaan](https://cran.r-project.org/web/packages/lavaan/index.html), which you might learn more about [here](https://dornsife.usc.edu/assets/sites/210/docs/GC3/lavaan_tutorial.pdf) or [here](http://lavaan.ugent.be/tutorial/index.html).

```{r, message = F, warning = F}
library(lavaan)
```

### 0-lag.

The simplest starting place is a p-technique factor analysis. Using this approach, the model syntax looks much like that of a typical group-level CFA. First, we specify the model, which we call `CFA_0_lag`. We define our sole factor `H` by the five items. By default, lavaan fixes the first loading of each factor to 1 in order to set the latent scale. With the `NA*A10` syntax, we relax that constraint, allowing lavaan to freely estimate all loadings. Correspondingly, we used the `H ~~ 1*H` syntax to set the latent variance to 1, which then set the scale of the latent by putting it in a standardized metric.

The way one scales a factor is largely a matter of taste. Interested readers might learn more about the three most common methods in [Little, Slegers and Card's (2006) article](http://www.agencylab.ku.edu/~agencylab/manuscripts/(Little,%20Slegers,%20Card,%202006).pdf) on the topic. We use the fixed factor method, here, to aid the interpretation of the effects in subsequent models.

```{r}
CFA_0_lag <- '
H =~ NA*A10 + A13 + A14 + A16 + A17

# Standardize the variance
H ~~ 1*H
'
```

Now we've defined the model, here we estimate the parameters. Note we've selected a robust estimator with the `estimator = "MLR"` syntax. The lavaan package offers a [variety of estimators](http://lavaan.ugent.be/tutorial/est.html), in addition to conventional maximum likelihood. With the `missing = "ML"` syntax, you’ll note we’re also handling the missing data with full information maximum likelihood (FIML) under the typical MAR assumption. As our p-technique models are just special cases of SEM, all of the modern missing data techniques (e.g., auxiliary variables with the saturated-correlates approach, multiple imputation) are available. For an approachable introduction contemporary missing data methods, see Enders' [*Applied missing data analysis*](http://www.appliedmissingdata.com). As our primary focus in this project is practicing with the p-technique models, we’ll keep things simple and just use FIML.

```{r, warning = F}
fit.CFA_0_lag <- 
  cfa(CFA_0_lag, 
      data = d,
      estimator = "MLR",
      missing = "ML")
```

Now we use the `summary()` function to return the results, including the typical fit indices and 95% CIs for good measure.

```{r}
summary(fit.CFA_0_lag, 
        fit.measures = T,
        standardized = T,
        ci = T)
```

The measures of model fit generally look good. We might note, however, that since this model has a small number of degrees of freedom (i.e., $df = 10$), the RMSEA is of limited utility, here. For more on the topic, see [Kenney, Kaniskan and McCoach (2015)](https://www.researchgate.net/publication/274053733_The_Performance_of_RMSEA_in_Models_With_Small_Degrees_of_Freedom). But RMSEA aside, the model $\chi^2$ and the CFI both look great. 

If you inspect the `Std.all` column, you'll see that for Lindsey, items 10 and 16 have very low standardized loadings. Results like this are where p-technique methods shine. Even though both items have high loadings in group-level factor analyses, those results do not necessarily hold for individuals. Even though Lindsey selected both items as among her primary ADHD concerns, they provide little information to her hyperactive factor.

The p-technique literature is surfeit with analyses showing the mismatch between group-based factor structures and those of single-case data. For introductions to the topic, consider [Fisher, Medaglia, and Jeronimus (2018)](https://www.pnas.org/content/pnas/early/2018/06/15/1711978115.full.pdf) or [Molenaar and Campbell (2009)](https://journals.sagepub.com/doi/pdf/10.1111/j.1467-8721.2009.01619.x).

### 1-lag.

#### First, we need to process the data a bit.

Before we proceed to fit a dynamic-p CFA, we'll need to lag our data file. In short, a lag is the difference from one measurement occasion to another. The duration of a lag will depend on study design. From the clinical process literature, for example, lags have ranged from utterance to utterance to the span between therapy sessions ([Russell, Jones, & Miller, 2007](https://www.researchgate.net/profile/Steven_Miller17/publication/247575796_Core_process_components_in_psychotherapy_A_synthetic_review_of_P-technique_studies/links/00463533b285620a84000000.pdf)). Since Lindsey's data are from a daily-diary study, each lag is a day in separation. 

Before we lag the data file, we'll add a row to the end of the data. Because this row corresponds to `Date = "2016-05-11"`, a day for which we don't have any information other than it was a Wednesday, we'll insert NAs into most of the columns.

```{r}
d_lagged <-
  tibble(Date = ymd("2016-01-18"), 
          Meds = NA, 
          A10 = NA, A13 = NA, A14 = NA, A16 = NA, A17 = NA) %>% 
  bind_rows(d)
```

With the `lead()` function, we'll add lagged values for our `Meds` dummy and our ASRS items. For each of the lagged columns, we'll add the suffix `_1` to help differentiate them from the original columns. 

```{r}
d_lagged <-
  d_lagged %>% 
  mutate(Meds_1 = lead(Meds),
         A10_1  = lead(A10),
         A13_1  = lead(A13),
         A14_1  = lead(A14),
         A16_1  = lead(A16),
         A17_1  = lead(A17))

glimpse(d_lagged)
```

Let's focus on the last four rows to take a closer look at what we've done. Here we'll just consider the `Date` and the original and lagged versions of items 10 and 13.

```{r}
d_lagged %>% 
  select(Date, A10:A13, A10_1:A13_1) %>%
  slice(c(101:104)) %>% 
  knitr::kable()
```

Notice how the values of `A10` and `A13` in one row are always the same as `A10_1` and `A13_1` in the row above them. That’s because when we created the lagged variables, those with the `_1` suffixes, we took the values from the original columns and shifted them up one. As such, the new lagged columns always have missing values in their last row. Because we did not collect data from Lindsey on May 11, we have no values to on her ASRS items to shift up one and insert into the lagged columns for May 10.

In principle, we could add more lags. [Kim, Nesselroade, and McCullough (2009)](https://link.springer.com/article/10.1007/s10804-009-9062-2), for example, used a 2-lag structure in their study on worldview, self-concept, and physical health in older individuals. For our present analysis, you might consider the original columns as depicting the data at *lag 0* and the new lagged columns as depicting the data at *lag 1*. Conceptually, lag 0 corresponds to "today" and lag 1 to "tomorrow." That is, the 1-lag data structure for daily-diary data allows to ask questions about how today will predict or influence tomorrow. If this is still confusing, see Little's (2013) text, particularly his Figure 7.7 and the prose surrounding it. This should also become more clear with a little practice.

#### We digress into measurement theory.

Now we have our lagged data, `d_lagged`, we are almost ready to specify and fit the 1-lag CFA model.

Because of the way the data are copied to create a lagged dataset, model estimation involving multiple lags entails a number of specific constraints because the information across the lags is essentially equivalent (Little, 2013). These constraints are all connected to the issue of measurement invariance. Typical group-level longitudinal CFAs require that analysts assess the extent to which the factors are invariant across time (for detailed discussions, see [Brown, 2015](https://www.guilford.com/books/Confirmatory-Factor-Analysis-for-Applied-Research/Timothy-Brown/9781462515363); Little, 2013; [Newsom, 2015](https://www.routledge.com/Longitudinal-Structural-Equation-Modeling-A-Comprehensive-Introduction/Newsom/p/book/9781848726970); [Widaman, Ferrer, & Conger, 2010](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2848495/pdf/nihms144397.pdf)). Factorial invariance across time suggests the variables of interest were reliably measured across time and that the constructs themselves were stable. For dynamic p-technique models, we expect "strict factorial invariance" (Little, 2013), which entails that the item loadings, item intercepts, and residual variances are equivalent across lags. 

We will specify those constraints using parameter labels in the code that follows. If you are completely new to measurement invariance within the SEM context, we provide a brief walk-through at the end of this project. But for a more thorough introduction, do spend some time with one or a few of the references, above.

#### Finally, we're ready to specify and estimate the model.

Within lavaan, assigning two or more parameters the same label will constrain them to equality. For example, consider the loading code, below. We define the lag-0 factor with the following: `H0 =~ l1*A10 + l2*A13 + l3*A14 + l4*A16 + l5*A17`. With the `l[i]*` prefixes, we labeled the loading of ASRS item 10 as `l1`, the loading for item 13 as `l2`, and so on. If you look at the second line, you'll see we used the same parameter labels for the lag-1 items. In this way, we constrain the loadings of the same items to equality across lags. We followed the same approach for the item intercepts and residual variances. 

The particular names you use for your labels are, of course, arbitrary. We could have named our first loading `dog` if we wanted to. Buy my stance is it makes sense to serially name parameters in the order they come in (e.g., `l1`, `l2`, ...) and to give groups of parameters the same prefix (e.g., `l` for loadings, `i` for intercepts). 

```{r}
CFA_1_lag <- '
# loadings
H0 =~ l1*A10   + l2*A13   + l3*A14   + l4*A16   + l5*A17
H1 =~ l1*A10_1 + l2*A13_1 + l3*A14_1 + l4*A16_1 + l5*A17_1

# item intercepts
A10 ~ i1*1
A13 ~ i2*1
A14 ~ i3*1
A16 ~ i4*1
A17 ~ i5*1

A10_1 ~ i1*1
A13_1 ~ i2*1
A14_1 ~ i3*1
A16_1 ~ i4*1
A17_1 ~ i5*1

# residual variances
A10 ~~ rv1*A10
A13 ~~ rv2*A13
A14 ~~ rv3*A14
A16 ~~ rv4*A16
A17 ~~ rv5*A17

A10_1 ~~ rv1*A10_1
A13_1 ~~ rv2*A13_1
A14_1 ~~ rv3*A14_1
A16_1 ~~ rv4*A16_1
A17_1 ~~ rv5*A17_1

# cross-lag residual covariances
A10 ~~ A10_1
A13 ~~ A13_1
A14 ~~ A14_1
A16 ~~ A16_1
A17 ~~ A17_1

# Structural model
H1 ~ H0

# latent variances
H0 ~~ 1*H0
H1 ~~ NA*H1 # Because of the structural model, the residual variance for H1 is freely estimated

# latent means/intercepts
H0 ~ 0
H1 ~ 1 # Because of the structural model, the latent intercept for H1 is freely estimated
'
```

We fit the model, here.

```{r}
fit.CFA_1_lag <- 
  cfa(CFA_1_lag, 
      data = d_lagged,
      estimator = "MLR",
      missing = "ML",
      std.lv = T)
```

The summary:

```{r}
summary(fit.CFA_1_lag, 
        fit.measures = T,
        standardized = T,
        ci = T)
```

The model fits the data great. You'll note that the autoregressive parameter, `H1 ~ H0`, is about .5. The metric is standardized and suggests that a one-unit increase in Lindsey's ASRS ratings, today, would predict about a half unit increase, tomorrow. You might interpret this as a carryover effect, or a kind of behavioral inertia. For more on the inertia interpretation, see [Hamaker, Asparouhov, Brose, Schmiedek, and Muthén (2018)](https://www.tandfonline.com/doi/full/10.1080/00273171.2018.1446819).

As an aside, you might also note that now our degrees of freedom are large enough (i.e., $df = 42$) that the RMSEA should be more informative. For example, the width of its upper 90% CI is much more narrow than it was in the first model. Happily, the RMSEA coheres with the other fit statistics, which all suggest the model fits the data well.

## Dynamic-p SEM

Here we move from measurement model concerns to include a covariate. With the data in hand, we can use `Meds_1` to predict lag-1 ADHD values, `H1`, while still controlling for the previous day's ADHD values (i.e., `H1 ~ H0`). The same measurement invariance constraints remain imposed.

```{r}
SEM_1_lag <- '
# loadings
H0 =~ l1*A10   + l2*A13   + l3*A14   + l4*A16   + l5*A17
H1 =~ l1*A10_1 + l2*A13_1 + l3*A14_1 + l4*A16_1 + l5*A17_1

# item intercepts
A10 ~ i1*1
A13 ~ i2*1
A14 ~ i3*1
A16 ~ i4*1
A17 ~ i5*1

A10_1 ~ i1*1
A13_1 ~ i2*1
A14_1 ~ i3*1
A16_1 ~ i4*1
A17_1 ~ i5*1

# residual variances
A10 ~~ rv1*A10
A13 ~~ rv2*A13
A14 ~~ rv3*A14
A16 ~~ rv4*A16
A17 ~~ rv5*A17

A10_1 ~~ rv1*A10_1
A13_1 ~~ rv2*A13_1
A14_1 ~~ rv3*A14_1
A16_1 ~~ rv4*A16_1
A17_1 ~~ rv5*A17_1

# cross-lag residual covariances
A10 ~~ A10_1
A13 ~~ A13_1
A14 ~~ A14_1
A16 ~~ A16_1
A17 ~~ A17_1

# Structural model
H1 ~ H0 + Meds_1

# LV variances
H0 ~~ 1*H0
H1 ~~ NA*H1 # Because of the structural model, the resitual variance for H1 is freely estimated

# latent means/intercepts
H0 ~ 0
H1 ~ 1 # Because of the structural model, the latent intercept for H1 is freely estimated
'
```

Fit the model.

```{r}
fit.SEM_1_lag <- 
  cfa(SEM_1_lag, 
      data = d_lagged,
      estimator = "MLR",
      missing = "ML",
      std.lv = T)
```

Now we summarize.

```{r}
summary(fit.SEM_1_lag, 
        fit.measures = T,
        standardized = T,
        ci = T)
```

The model fit the data well. Recall that the latent variables are in a standardized metric. Because `Meds_1` is a dummy variable, this puts its coefficient in a Cohen's $d$ like metric.

## Dynamic-p SEM part 2: Longitudinal mediation

To demonstrate the flexibility of the dynamic p-technique SEM framework, we might reparameterize the structural model to make a longitudinal mediation model. We will continue to regress `H1` on both `H0` and `Meds_1`. Now we also regress `Meds_1` on `H0`. Within the consider the typical mediation path diagram. 

<insert figure>

If we are interested in quantifying the strength of the indirect effect of X on Y through M, we multiply the $a$ and $b$ pathways. Because the sampling distribution of the $ab$ coefficient is not necessarily Gaussian, contemporary methodologists typically recommend using the bootstrap to compute the 95% confidence intervals rather than rely on analytic standard errors (e.g., [Hayes & Rockwood, 2017](https://reader.elsevier.com/reader/sd/pii/S0005796716301887?token=88A7F6370B3BC1D9C162157418E77467F140B779DE8A0E2922DA5C602199371FB681DC979A2DB3EA50C7B3637AE2470C)). All of this is [available with lavaan](http://lavaan.ugent.be/tutorial/mediation.html). 

Now consider our new structural model.

```{r, eval = F}
'
H1     ~ H0 + Meds_1
Meds_1 ~ H0
'
```

In this model, we might consider `H1` as the $Y$ variable, `H0` as the $X$, and `Meds_1` as the mediator $M$. As such, we can label the parameters like so.

```{r, eval = F}
'
H1     ~ c*H0 + b*Meds_1
Meds_1 ~ a*H0
'
```

Now all we need to do is use the `:=` operator to define the `ab` parameter and fit the model.

```{r}
MED_1_lag <- '
# loadings
H0 =~ l1*A10   + l2*A13   + l3*A14   + l4*A16   + l5*A17
H1 =~ l1*A10_1 + l2*A13_1 + l3*A14_1 + l4*A16_1 + l5*A17_1

# item intercepts
A10 ~ i1*1
A13 ~ i2*1
A14 ~ i3*1
A16 ~ i4*1
A17 ~ i5*1

A10_1 ~ i1*1
A13_1 ~ i2*1
A14_1 ~ i3*1
A16_1 ~ i4*1
A17_1 ~ i5*1

# residual variances
A10 ~~ rv1*A10
A13 ~~ rv2*A13
A14 ~~ rv3*A14
A16 ~~ rv4*A16
A17 ~~ rv5*A17

A10_1 ~~ rv1*A10_1
A13_1 ~~ rv2*A13_1
A14_1 ~~ rv3*A14_1
A16_1 ~~ rv4*A16_1
A17_1 ~~ rv5*A17_1

# cross-lag residual covariances
A10 ~~ A10_1
A13 ~~ A13_1
A14 ~~ A14_1
A16 ~~ A16_1
A17 ~~ A17_1

# Structural model
H1     ~ c*H0 + b*Meds_1
Meds_1 ~ a*H0

# LV variances
H0 ~~ 1*H0
H1 ~~ NA*H1 # Because of the structural model, the resitual variance for H1 is freely estimated

# latent means/intercepts
H0 ~ 0
H1 ~ 1 # Because of the structural model, the latent intercept for H1 is freely estimated

# model constraint
ab := a * b
'
```

lavaan offers at least two ways to bootstrap. Perhaps the simplest is to include `se = "bootstrap"` within the `cfa()` or `sem()` functions. By default, it returns results from 1000 iterations. Note, however, that this requires we set `estimator = "ML"`.

```{r, message = F, warning = F}
fit.MED_1_lag <- 
  cfa(MED_1_lag, 
      data = d_lagged,
      estimator = "ML",
      missing = "ML",
      std.lv = T,
      se = "bootstrap")
```

Behold the summary.

```{r}
summary(fit.MED_1_lag, 
        fit.measures = T,
        ci = T)
```

Based on the $\chi^2$ and so forth, the model continues to fit the data just fine. The `ab` parameter is small but with modestly narrow intervals not overlapping zero. Here we have statistical evidence of a single-subject mediational process.

To be clear, this is not a theory-based model and we would not encourage our readers to over interpret these results. But we do hope applied researchers might find the example provocative. By combining sound theory, carefully-collected single-case data, and the dynamic p-technique framework, researchers can fit single-case mediation models and more.

## Happy modeling

Consider again the challenge made by [Hayes and colleagues](https://www.sciencedirect.com/science/article/pii/S000579671830158X):

> Individual human lives are contextual and longitudinal, as are the change processes that alter these life trajectories. From a process-based point of view, practitioners need coherent and broadly applicable models of change processes that are relevant for the individual in context, that provide increased treatment utility and intervention guidance, and that simplify human complexity. The most popular methodological and analytic tools in use in intervention science are not fully adequate to that task, even when they are turned in the direction of change processes. (p. 3)

We believe the p-technique framework may be up to the task.

Happy modeling.

## What's the deal with measurement invariance?

## References

Brown, T. A. (2015). *Confirmatory factor analysis for applied research*. New York, NY: Guilford Press.

Enders, C. K. (2010). *Applied missing data analysis*. New York, NY US: Guilford Press. 

Fisher, A. J., Medaglia, J. D., & Jeronimus, B. F. (2018). Lack of group-to-individual generalizability is a threat to human subjects research. *Proceedings of the National Academy of Sciences*. doi: 10.1073/pnas.1711978115

Hamaker, E. L., Asparouhov, T., Brose, A., Schmiedek, F., & Muthén, B. (2018). At the frontiers of modeling intensive longitudinal data: Dynamic structural equation models for the affective measurements from the COGITO study. *Multivariate Behavioral Research*, doi:10.1080/00273171.2018.1446819

Hayes, A. F., & Rockwood, N. J. (2017). Regression-based statistical mediation and moderation analysis in clinical research: Observations, recommendations, and implementation. *Behaviour Research & Therapy, 98*, 39–57. doi: 10.1016/j.brat.2016.11.001

Hayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Stanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2018). The role of the individual in the coming era of process-based therapy. *Behavior Research and Therapy*. doi: 10.1016/j.brat.2018.10.005

Kenny, D. A., Kaniskan, B., & McCoach, D. B. (2015). The performance of RMSEA in models with small degrees of freedom. *Sociological Methods & Research, 44*, 486–507. doi: 10.1177/0049124114543236

Kim, J., Nesselroade, J., & McCullough, M. (2009). Dynamic factor analysis of worldview/religious beliefs and well-being among older adults. *Journal of Adult Development, 16*, 87-100. doi: 10.1007/s10804-009-9062-2

Little, T. D. (2013). *Longitudinal structural equation modeling*. New York, NY: The Guilford Press. 

Little, T. D., Slegers, D. W., & Card, N. A. (2006). A non-arbitrary method of identifying and scaling
latent variables in SEM and MACS models. *Structural Equation Modeling, 13*, 59–72.

Molenaar, P. C. M., & Campbell, C. G. (2009). The new person-specific paradigm in psychology, *Current Directions in Psychological Science, 18*, 112–117. doi: 10.1111/j.1467-8721.2009.01619.x

Newsom, J. T. (2015). *Longitudinal Structural Equation Modelling*. London: Routledge.

Russell, R. L., Jones, M. E., & Miller, S. A. (2007). Core process components in psychotherapy: A synthetic review of p-technique studies. *Psychotherapy Research, 17*, 273–291. doi:10.1080/10503300500529388

Widaman, K. F., Ferrer, E., & Conger, R. D. (2010). Factorial invariance within longitudinal structural equation models: Measuring the same construct across time. *Child Development Perspectives, 4*, 10–18. doi:10.1111/j.1750-8606.2009.00110.x

## Session Info

To help make this work more reproducible, here's the session information.

```{r}
sessionInfo()
```

